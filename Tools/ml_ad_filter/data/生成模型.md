# AI 广告关键词提取模型训练指南

本指南介绍如何训练 AI 关键词提取模型用于 AI 广告过滤功能。

## 新架构说明

新架构采用**关键词特征库**模式：

1. **AI关键词提取模型**：从消息文本中提取广告关键词及频次
2. **AI广告关键词特征库**：存储关键词特征（权重、频次、分类、来源）
3. **广告判定逻辑**：提取关键词 → 与特征库比对 → 频次加权计算得分 → 判定是否为广告

## 使用 Google Colab

### 步骤 1：打开 Colab

访问 https://colab.research.google.com/ 并新建笔记本

### 步骤 2：上传训练数据

将 `tools/ml_ad_filter/data/train.csv` 上传到 Colab

### 步骤 3：训练关键词提取模型

```python
# 1. 安装依赖
!pip install tensorflow pandas scikit-learn -q

# 2. 上传数据
from google.colab import files
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import re
import json

# 上传 train.csv
files.upload()

# 3. 加载训练数据
df = pd.read_csv('train.csv')
print(f"总样本数: {len(df)}")
print(f"广告样本: {len(df[df['label']=='ad'])}")
print(f"正常样本: {len(df[df['label']=='normal'])}")

# 4. 文本预处理（处理异型字）
def normalize_text(text):
    """标准化文本，处理异型字"""
    if pd.isna(text):
        return ""
    text = str(text)
    # 替换常见异型字
    replacements = {
        '薇': '微', '丄': '上', '沖': '冲', '値': '值',
        '玳': '代', '菠': '博', '菜': '彩',
        'Ⓑ': 'B', 'Ⓒ': 'C',
        'v.x': 'vx', 'V.X': 'VX', 'V X': 'VX',
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    # 移除零宽字符
    text = re.sub(r'[\u200b-\u200f\ufeff]', '', text)
    return text

df['text_normalized'] = df['text'].apply(normalize_text)

# 5. 解析关键词标签
def parse_keywords(keywords_str):
    """解析关键词字符串"""
    if pd.isna(keywords_str) or keywords_str == '':
        return []
    return [k.strip() for k in keywords_str.split('|') if k.strip()]

df['keywords_list'] = df['keywords'].apply(parse_keywords)

# ============================================
# 训练关键词提取模型
# ============================================
print("\n" + "="*50)
print("训练关键词提取模型")
print("="*50)

# 准备训练数据
# 为每个样本构建关键词标签向量
all_keywords = set()
for keywords in df['keywords_list']:
    all_keywords.update(keywords)
all_keywords = sorted(list(all_keywords))
keyword_to_idx = {k: i for i, k in enumerate(all_keywords)}
idx_to_keyword = {i: k for k, i in keyword_to_idx.items()}

print(f"关键词总数: {len(all_keywords)}")
print(f"关键词列表: {all_keywords[:20]}...")  # 显示前20个

# 构建多标签目标
y = np.zeros((len(df), len(all_keywords)))
for i, keywords in enumerate(df['keywords_list']):
    for kw in keywords:
        if kw in keyword_to_idx:
            y[i, keyword_to_idx[kw]] = 1.0

# 分割数据
X_train, X_test, y_train, y_test = train_test_split(
    df['text_normalized'].tolist(), y, test_size=0.2, random_state=42
)

# TF-IDF 特征提取
vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))
X_train_tfidf = vectorizer.fit_transform(X_train).toarray()
X_test_tfidf = vectorizer.transform(X_test).toarray()

# 构建关键词提取模型（多标签分类）
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train_tfidf.shape[1],)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(len(all_keywords), activation='sigmoid')  # 多标签输出
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# 训练
history = model.fit(X_train_tfidf, y_train,
                   epochs=20, batch_size=32,
                   validation_data=(X_test_tfidf, y_test),
                   verbose=1)

# 评估
loss, acc = model.evaluate(X_test_tfidf, y_test)
print(f"模型测试集准确率: {acc:.4f}")

# 保存模型
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('keyword_extractor_model.tflite', 'wb') as f:
    f.write(tflite_model)

# 保存关键词列表
with open('keyword_extractor_labels.txt', 'w', encoding='utf-8') as f:
    for kw in all_keywords:
        f.write(f"{kw}\n")

# 保存词汇表
vocab = vectorizer.vocabulary_
with open('keyword_extractor_vocab.txt', 'w', encoding='utf-8') as f:
    for word, idx in sorted(vocab.items(), key=lambda x: x[1]):
        f.write(f"{word}\n")

# 保存 IDF 值
idf = vectorizer.idf_
with open('keyword_extractor_idf.txt', 'w') as f:
    for val in idf:
        f.write(f"{val}\n")

# 保存配置
config = {
    'max_features': vectorizer.max_features,
    'ngram_range': list(vectorizer.ngram_range),
    'vocab_size': len(vocab),
    'keyword_count': len(all_keywords),
    'model_type': 'multi_label_classification'
}
with open('keyword_extractor_config.json', 'w') as f:
    json.dump(config, f, indent=2)

print("关键词提取模型训练完成！")
print(f"词汇表大小: {len(vocab)}")
print(f"关键词数量: {len(all_keywords)}")
print(f"配置: {config}")

# ============================================
# 生成初始特征库
# ============================================
print("\n" + "="*50)
print("生成初始特征库")
print("="*50)

# 基于训练数据统计关键词权重
keyword_stats = {}
for i, row in df.iterrows():
    if row['label'] == 'ad':
        for kw in row['keywords_list']:
            if kw not in keyword_stats:
                keyword_stats[kw] = {'count': 0, 'total_weight': 0}
            keyword_stats[kw]['count'] += 1

# 计算权重（基于出现频次）
max_count = max(stats['count'] for stats in keyword_stats.values()) if keyword_stats else 1

with open('ad_feature_library.txt', 'w', encoding='utf-8') as f:
    f.write("# AI广告关键词特征库\n")
    f.write("# 格式：关键词,权重,频次,分类,来源\n")
    f.write("# 权重范围：0.0-1.0\n")
    f.write("# 分类：ad(广告), normal(正常)\n")
    f.write("# 来源：ai_extracted(AI提取), manual(手动添加)\n")
    f.write("\n")

    for kw, stats in sorted(keyword_stats.items(), key=lambda x: x[1]['count'], reverse=True):
        weight = min(0.95, 0.5 + (stats['count'] / max_count) * 0.45)
        f.write(f"{kw},{weight:.2f},{stats['count']},ad,ai_extracted\n")

print(f"特征库已生成，包含 {len(keyword_stats)} 个关键词")

# ============================================
# 下载所有模型文件
# ============================================
print("\n" + "="*50)
print("下载模型文件")
print("="*50)

files.download('keyword_extractor_model.tflite')
files.download('keyword_extractor_labels.txt')
files.download('keyword_extractor_vocab.txt')
files.download('keyword_extractor_idf.txt')
files.download('keyword_extractor_config.json')
files.download('ad_feature_library.txt')

print("所有文件已下载！")
print("\n部署到 Android 项目的文件列表：")
print("TMessagesProj/src/main/assets/ai_ad_filter/")
print("├── keyword_extractor_model.tflite    # 关键词提取模型")
print("├── keyword_extractor_labels.txt      # 关键词标签")
print("├── keyword_extractor_vocab.txt       # 词汇表")
print("├── keyword_extractor_idf.txt        # IDF值")
print("└── ad_feature_library.txt           # 初始特征库")
```

### 步骤 4：部署模型

将下载的文件放入以下目录：

```
TMessagesProj/src/main/assets/ai_ad_filter/
├── keyword_extractor_model.tflite      # 关键词提取模型
├── keyword_extractor_labels.txt        # 关键词标签
├── keyword_extractor_vocab.txt         # 词汇表
├── keyword_extractor_idf.txt          # IDF值
├── keyword_extractor_config.json      # 模型配置
└── ad_feature_library.txt             # 初始特征库
```

## 训练数据格式

### 新格式

```csv
text,label,keywords
"专业上分服务，安全可靠，微信：bet888",ad,"上分|微信|博彩"
"你好，最近怎么样？",normal,""
"跑分兼职，日赚500-2000",ad,"跑分|兼职|赚钱"
```

### 字段说明

- `text`: 消息文本内容
- `label`: 标签（`ad` 表示广告，`normal` 表示正常消息）
- `keywords`: 关键词列表，用 `|` 分隔。广告样本填写提取的关键词，正常样本留空

### 关键词标注规范

1. **核心广告词**：博彩、跑分、上分、下分、刷单、返利等（权重0.9+）
2. **交易相关词**：充值、收款码、代收、代付、USDT等（权重0.8+）
3. **招募相关词**：代理、招募、加盟、兼职、月入过万等（权重0.7+）
4. **联系方式词**：微信、QQ、私聊、联系等（权重0.5+）

### 异型字处理

训练数据应包含以下类型的异型字样本：

1. **同音字替换**：薇信(微信)、丄分(上分)
2. **形近字替换**：沖值(充值)、値(值)
3. **字母替换**：ⒷⒸ(BC)、v.x(vx)
4. **分隔符**：博.彩、代.理
5. **空格分隔**：B o C、V X

## 模型配置

### 关键词提取模型参数

| 参数 | 值 | 说明 |
|------|-----|------|
| max_features | 10000 | TF-IDF 最大特征数 |
| ngram_range | (1, 3) | 使用 1-gram、2-gram、3-gram |
| 隐藏层 | 256 -> 128 -> 64 | 神经网络结构 |
| 输出层 | N (sigmoid) | 多标签输出，N为关键词数量 |
| 损失函数 | Binary Crossentropy | 二分类交叉熵 |
| epochs | 20 | 训练轮数 |
| batch_size | 32 | 批次大小 |
| dropout | 0.3-0.4 | 防止过拟合 |

### 特征库格式

```
# AI广告关键词特征库
# 格式：关键词,权重,频次,分类,来源
# 权重范围：0.0-1.0
# 分类：ad(广告), normal(正常)
# 来源：ai_extracted(AI提取), manual(手动添加)

博彩,0.95,150,ad,ai_extracted
跑分,0.92,120,ad,ai_extracted
上分,0.90,100,ad,ai_extracted
```

## 应用配置

### 阈值设置

在应用设置中可以调整AI广告判定阈值：

- **AI广告判定阈值**：默认 0.5
  - 范围：0.0 - 1.0
  - 值越高，过滤越严格，可能漏判
  - 值越低，过滤越宽松，可能误判
  - 建议值：0.5-0.7

### 过滤流程

1. 消息输入 → AI关键词提取模型提取关键词及频次
2. 提取的关键词与特征库比对，获取权重
3. 计算得分 = Σ(权重 × 频次^1.2) + 高频加分 + 多词加分
4. 得分 ≥ 阈值 → 判定为广告

### 用户反馈机制

用户可以通过长按消息选择"AI关键词特征提取"：
1. AI模型分析消息内容，提取潜在广告关键词
2. 显示提取结果，用户选择要添加的关键词
3. 选中的关键词加入特征库，来源标记为 `ai_extracted`

## 故障排除

### 模型预测不准确

1. **增加训练数据**：特别是边界案例
2. **调整特征提取**：
   - 增加 `max_features` 到 15000
   - 调整 `ngram_range` 到 (1, 4)
3. **调整网络结构**：
   - 增加隐藏层神经元数量
   - 增加层数

### 关键词提取不完整

1. 确保训练数据中的关键词标注完整
2. 增加关键词覆盖范围
3. 调整模型输出阈值

### 模型文件过大

1. 减小 `max_features`
2. 减少关键词数量（只保留高频关键词）
3. 使用更简单的网络结构
4. 启用更多优化选项：
   ```python
   converter.optimizations = [tf.lite.Optimize.DEFAULT]
   converter.target_spec.supported_types = [tf.float16]
   ```

### TensorFlow 版本不兼容

```bash
pip install tensorflow==2.14.0
```

## 性能优化建议

1. **数据增强**：对广告样本进行同义词替换、语序调整
2. **类别平衡**：确保正负样本比例均衡
3. **交叉验证**：使用 K-fold 交叉验证评估模型
4. **早停策略**：防止过拟合
   ```python
   early_stop = tf.keras.callbacks.EarlyStopping(
       monitor='val_loss', patience=3, restore_best_weights=True
   )
   ```
